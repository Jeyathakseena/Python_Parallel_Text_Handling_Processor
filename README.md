
#  Python Parallel Text Handling Processor

##  Project Overview

This project focuses on building a text handling processor that works at the same time using Python's multi-tasking. It breaks up text, applies simple pattern finding, and stores results in a database for easy access.

The system uses CSV files for batch processing and provides summaries for analysis. It is designed to handle large text datasets efficiently, run tasks simultaneously such as rule-based sentiment scoring, and generate searchable records.

This project helps language experts and data workers analyze text efficiently without requiring advanced text processing tools.

---

##  Outcomes

* Scalable handling of text for quick processing.
* Accurate rule-based scoring of feelings and pattern detection.
* Structured and searchable text storage using a database.
* Improved text processing workflow with automated handling and reporting.

---

# ğŸ”¹ Task 1 â€“ Multithreaded Text Processing

###  Features

* Processes multiple text files in parallel using Python threading.
* Converts text content to lowercase for uniform processing.
* Applies rule-based sentiment scoring.
* Calculates total execution time for multitasking.

###  Technologies Used

* Python `threading` module

---

# ğŸ”¹ Task 2 â€“ SQLite Database Integration

###  Features

* Creates and manages a local SQLite database.
* Stores filename and sentiment score.
* Retrieves and displays stored records.
* Ensures proper database connection handling.

###  Technologies Used

* `sqlite3` module

---

# ğŸ”¹ Task 3 â€“ Hotel Review Sentiment Analysis

###  Features

* Uses TripAdvisor hotel review dataset (CSV format).
* Implements domain-specific rule-based scoring system.
* Performs aspect-based sentiment classification.
* Stores review text, score, sentiment, and timestamp in SQLite database.
* Includes proper exception handling for file and database operations.

###  Reviews Classification

Reviews are classified as:

* **Satisfied**
* **Dissatisfied**
* **Neutral**




###  Technologies Used

* `csv` module
* `sqlite3`
* `datetime`

---

## ğŸ”¹ Task 4 â€“ Performance & Optimization Test

â— Processed a large dataset (~1 million records simulated using repeated CSV data).

â— Inserted scored records into SQLite database.

â— Measured:

* Insert execution time
* Query execution time

â— Applied table optimization using indexing on `overall_sentiment` column.

â— Re-ran the same query and recorded new execution time.

â— Compared performance before and after optimization.



### Technologies Used:

â— sqlite3

â— time module (execution time measurement)

â— CSV dataset processing

â— SQL indexing

---

